Projet : Le scrappeur fou
  
1. Introduction
Aujourd'hui, tu vas automatiser la rÃ©cupÃ©ration massive de donnÃ©es issus de sites internet (= tu vas scraper). Tes compÃ©tences en Ruby et en HTML vont te permettre de rÃ©cupÃ©rer ces informations en moins d'une journÃ©e. Tu t'amuseras avec le cours des cryptomonnaies, tu iras rÃ©cupÃ©rer les e-mails des mairies de notre beau pays, puis tu chopperas la liste des e-mails des dÃ©putÃ©s de France. Tu ne te penses pas capable de tout Ã§a ? Et bien tu vas voir que si.

Les standards habituels seront attendus : un dossier bien rangÃ©, de beaux README et Gemfile, des tests qui vÃ©rifient que tout fonctionne.

2. Le projet
2.1. Initialize
Commence par crÃ©er une structure de dossier propre avec le dossier lib, le dossier spec, etc. CrÃ©Ã© un Gemfile, un README et fais ton $ git init. Maintenant on peut commencer Ã  travailler ğŸ˜˜

2.2. Dark Trader
Lehman Brothers, impressionnÃ©s par ton algorithme d'optimisation d'achat / vente, veut encore faire appel Ã  toi. Leur Chief Digital Officer, trÃ¨s hype, a entendu parler au JT de TF1 d'un "truc rÃ©volutionnaire qui s'appelle le bloque-chienne". Il veut en acheter plein. Pour le conseiller, tu vas devoir rÃ©cupÃ©rer le cours de toutes les cryptomonnaies du marchÃ©.

En prenant pour source le site CoinMarketCap, fait un programme qui rÃ©cupÃ¨re le cours de toutes les cryptomonnaies et les enregistre bien proprement dans un array de hashs.
Ton array devra avoir le format suivant :

a = [
  { "BTC" => 5245.12 },
  { "ETH" => 217.34 }, 
  etc
]
Pour les tests, inspire-toi de la ressource plus haut. Il n'y a pas besoin de faire 36 000 tests, il faut juste arriver Ã  tester 1) le fonctionnement de base de ton programme (pas d'erreur ni de retour vide) et 2) que ton programme sort bien un array cohÃ©rent (vÃ©rifier la prÃ©sence de 2-3 cryptomonnaies, vÃ©rifier que lâ€™array est de taille cohÃ©rente, etc.).

Quelques petites aides pour ce premier exercice :

Il est possible de faire le programme en n'allant que sur une seule URL. C'est un bon moyen pour faire un programme rapide car ne chargeant pas 2000 pages HTML.
Tout se jouera sur la rÃ©daction d'un XPath pertinent et prÃ©cis qui extrait juste ce qu'il faut d'Ã©lÃ©ments HTML. Puis un bon traitement de ces Ã©lÃ©ments pour en extraire les 2 infos dont tu as besoin : le nom des crypto et leur cours.
Un programme qui scrappe sans rien te dire, c'est non seulement nul mais en plus, tu ne sais pas s'il marche, s'il tourne en boucle ou sâ€™il attend que ton wifi fonctionne. Mets des puts dans ton code pour que ton terminal affiche quelque chose Ã  chaque fois qu'il a pu rÃ©cupÃ©rer une donnÃ©e. Comme Ã§a tu vois ton scrappeur qui fonctionne et avec des mots qui apparaissent tout seul sur ton terminal, tu vas donner l'impression que t'es un hacker. StylaÃ¯.
Pense Ã  bien nommer tes variables pour ne pas te perdre ! Par exemple, quand tu as un array, nomme-le crypto_name_array ou Ã  minima mets son nom au pluriel crypto_nameS. Sinon tu vas oublier que c'est un array et tu vas tenter des .text dessus alors qu'il faut bosser avec un .each.
Rappel: un hash sâ€™initialise avec result = Hash.new et on y stocke des infos avec result['ta_key'] = 'ta_value'
N'hÃ©site pas Ã  dÃ©couper ton programme en plusieurs Ã©tapes simples et dont le fonctionnement est facile Ã  vÃ©rifier. Par exemple : 1) Isoler les Ã©lÃ©ments HTML qui vont bien, 2) En extraire le texte et mettre Ã§a dans un hash, 3) RÃ©organiser ce hash dans un array de plusieurs mini-hash comme demandÃ©.
MÃªme si Ã§a n'est pas le chemin le plus court, l'essentiel est que chaque petite Ã©tape te fasse avancer et qu'Ã  chaque fois tu te dises "ok, Ã©tape 1), Ã§a fonctionne nickel - pas de bug. Passons Ã  la suite".
2.3. Mairie christmas
Le CEO de Get-email Corp a besoin de tes services. Il voudrait toutes les adresses e-mail des mairies du Val d'Oise. Aucun souci pour toi. Va sur cet annuaire des mairies et rÃ©cupÃ¨re les adresses e-mails des mairies du Val d'Oise. Comme pour l'exercice prÃ©cÃ©dent, tu devras enregistrer les donnÃ©es dans un array de hash suivant ce format :

a = [
  { "ville_1" => "email_1" },
  { "ville_2" => "email_2" }, 
  etc
]
DÃ©composons le programme en 2 sous-problÃ¨me simples:

Tu dois Ãªtre capable d'obtenir un e-mail de mairie Ã  partir de la page de cette derniÃ¨re (pas en partant du listing complet des mairies). Fais d'abord une mÃ©thode get_townhall_email(townhall_url) qui rÃ©cupÃ¨re lâ€™e-mail d'une mairie Ã  partir de l'URL de mairies, par exemple celle de Avernes.
Une fois que tu sais le faire pour une mairie, tu vas vouloir industrialiser et rÃ©pÃ©ter Ã§a sur tout l'annuaire du Val d'Oise. La prochaine Ã©tape est de coder une mÃ©thode get_townhall_urls qui rÃ©cupÃ¨re les URLs de chaque ville du Val d'Oise.
Quand tu es assez sÃ»r que chaque mÃ©thode marche sÃ©parÃ©ment, tu as juste Ã  imbriquer les deux et Ã  toi la gloire.

Pour les tests, ce sera la mÃªme chose que pour l'exercice prÃ©cÃ©dent mais appliquÃ© aux deux mÃ©thodes : des tests de fonctionnement de base et des tests de cohÃ©rence du rÃ©sultat.

2.4. Cher dÃ©putÃ©
Maintenant, fini de se faire mÃ¢cher le travail par tes gentils formateurs de THP. Tu dois rÃ©cupÃ©rer la liste complÃ¨te des dÃ©putÃ©s de France ainsi que leurs adresses e-mail. Cherche par toi-mÃªme le site le plus aisÃ© Ã  scrapper et stocke les informations extraites dans une array de hashs selon ce format (un peu diffÃ©rent des exercices prÃ©cÃ©dents) :

a = [
  { 
    "first_name" => "Jean",
    "last_name" => "Durant",
    "email" => "jean.durant@assemblÃ©e.fr"
  },
  { 
    "first_name" => "Martin",
    "last_name" => "Dupont",
    "email" => "martin.dupont@assemblÃ©e.fr"
  },
  etc
]
Pour les tests, nous t'invitons Ã  te poser et t'inspirer des tests prÃ©cÃ©dents. Deux tests suffiront.